{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "updatedProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQOkZrQzd-w"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ULGG1pFzgmO",
        "outputId": "55a1bdaf-cc57-4aaf-d46c-658cdb3160a1"
      },
      "source": [
        "pip install xmltodict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msfe13Aazi3d"
      },
      "source": [
        "import xmltodict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCUqRJUozkna",
        "outputId": "0469bf47-9ba0-4202-ab76-02c261150a39"
      },
      "source": [
        "cd drive/MyDrive/CSC474/Project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSC474/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r_DFMDwzmj1"
      },
      "source": [
        "images = []\n",
        "annotations = []\n",
        "\n",
        "image_dir = os.getcwd() + '/data/images'\n",
        "annot_dir = os.getcwd() + '/data/annotations'\n",
        "\n",
        "for filename in os.listdir(annot_dir):\n",
        "    annotations.append(filename)\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    images.append(filename)\n",
        "\n",
        "images = sorted(images)\n",
        "annotations = sorted(annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esfp4hUrzpE4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "bboxes = []\n",
        "dataimage = []\n",
        "classes = {'without_mask':0, 'with_mask':1, 'mask_weared_incorrect':2}\n",
        "\n",
        "for i in range (0,len(annotations)):\n",
        "    annot_file = open(os.path.join(annot_dir, annotations[i]), 'r')\n",
        "    image_filename = os.path.join(image_dir, images[i])\n",
        "\n",
        "    annot_data = annot_file.read()\n",
        "    annot_dict = xmltodict.parse(annot_data)['annotation']\n",
        "\n",
        "    image = Image.open(image_filename)\n",
        "\n",
        "    objects = annot_dict['object']\n",
        "    if isinstance(objects, list):\n",
        "        for item in objects:\n",
        "          xmin = int(item['bndbox']['xmin'])\n",
        "          ymin = int(item['bndbox']['ymin'])\n",
        "          xmax = int(item['bndbox']['xmax'])\n",
        "          ymax = int(item['bndbox']['ymax'])\n",
        "          label = classes[item['name']] # 1-hot encoding.\n",
        "\n",
        "          bbox = (xmin, ymin, xmax, ymax, label)\n",
        "          bboxes.append(bbox)\n",
        "  \n",
        "          image = image.resize((224,224), Image.ANTIALIAS)\n",
        "          image = image.convert(mode='RGB')\n",
        "          image_arr = img_to_array(image)\n",
        "          dataimage.append(image_arr)\n",
        "\n",
        "    else:\n",
        "        xmin = int(item['bndbox']['xmin'])\n",
        "        ymin = int(item['bndbox']['ymin'])\n",
        "        xmax = int(item['bndbox']['xmax'])\n",
        "        ymax = int(item['bndbox']['ymax'])\n",
        "        label = classes[item['name']] # 1-hot encoding.\n",
        "\n",
        "        bbox = (xmin, ymin, xmax, ymax, label)\n",
        "        bboxes.append(bbox)\n",
        "  \n",
        "        image = image.resize((224,224), Image.ANTIALIAS)\n",
        "        image = image.convert(mode='RGB')\n",
        "        image_arr = img_to_array(image)\n",
        "        dataimage.append(image_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEPDfo2szsu9"
      },
      "source": [
        "x = torch.from_numpy(np.array(dataimage))\n",
        "x = torch.unsqueeze(x, -1)\n",
        "x = x[0].reshape((1,3,224,224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJnpfOZ5zv7z"
      },
      "source": [
        "config = [\n",
        "    (32, 3, 1),\n",
        "    (64, 3, 2),\n",
        "    [\"B\", 1],\n",
        "    (128, 3, 2),\n",
        "    [\"B\", 2],\n",
        "    (256, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (512, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (1024, 3, 2),\n",
        "    [\"B\", 4],  # To this point is Darknet-53\n",
        "    (512, 1, 1),\n",
        "    (1024, 3, 1),\n",
        "    \"S\",\n",
        "    (256, 1, 1),\n",
        "    \"U\",\n",
        "    (256, 1, 1),\n",
        "    (512, 3, 1),\n",
        "    \"S\",\n",
        "    (128, 1, 1),\n",
        "    \"U\",\n",
        "    (128, 1, 1),\n",
        "    (256, 3, 1),\n",
        "    \"S\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6QUUz3Bzymn"
      },
      "source": [
        "# Hyperparameters\n",
        "leakyReLuAlpha = 0.1\n",
        "bn_momentum = 0.999\n",
        "conv_bias = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZEjRIB4z1HU"
      },
      "source": [
        "class yolo_model(nn.Module):\n",
        "\n",
        "    def __init__(self, leakyReLuAlpha = 0.1, bn_momentum = 0.999, usebias = False):\n",
        "        super(yolo_model, self).__init__()\n",
        "        self.leakyReLuAlpha = leakyReLuAlpha\n",
        "        self.bn_momentum = bn_momentum\n",
        "        self.usebias = usebias\n",
        "        self.layers = self.createModelLayers()\n",
        "\n",
        "    def createModelLayers(self):\n",
        "        layers = nn.ModuleList()\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(3, 32, 3, 1, bias= self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(32, 64, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' residual '''\n",
        "        layer1a = nn.Conv2d(64, 32, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(32, 64, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "        layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(64, 128, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 2 resiudal repeats '''\n",
        "        layer1a = nn.Conv2d(128, 64, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(64, 128, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(128, 256, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1a = nn.Conv2d(256, 128, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(128, 256, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,8):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 512, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1a = nn.Conv2d(512, 256, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(256, 512, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,8):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 1024, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 4 residual repeats '''\n",
        "        layer1a = nn.Conv2d(1024, 512, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "      \n",
        "        layer2a = nn.Conv2d(512, 1024, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,4):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(1024, 512, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(512, 1024, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(1024, 512, kernel_size=1, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(0.1)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size= 3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer,)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(768, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(256, 512, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(512, 256, kernel_size=1, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(0.1)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size= 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(384, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(128, 256, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(256, 128, kernel_size=1, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(0.1)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size= 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        return layers\n",
        "\n",
        "    def evaluateModel(self, inputtensor):\n",
        "        route = []\n",
        "        output = []\n",
        "        x = self.layers[0](inputtensor)\n",
        "        x = self.layers[1](x)\n",
        "        x = self.layers[2](x)\n",
        "        \n",
        "        x = self.layers[3](x)\n",
        "        x = self.layers[4](x)\n",
        "        x = self.layers[5](x)\n",
        "        \n",
        "        x = x + self.layers[6](x)\n",
        "        \n",
        "        x = self.layers[7](x)\n",
        "        x = self.layers[8](x)\n",
        "        x = self.layers[9](x)\n",
        "\n",
        "        x = x + self.layers[10](x)\n",
        "        x = x + self.layers[11](x)\n",
        "        \n",
        "        x = self.layers[12](x)\n",
        "        x = self.layers[13](x)\n",
        "        x = self.layers[14](x)\n",
        "        \n",
        "        x = x + self.layers[15](x)\n",
        "        x = x + self.layers[16](x)\n",
        "        x = x + self.layers[17](x)\n",
        "        x = x + self.layers[18](x)\n",
        "        x = x + self.layers[19](x)\n",
        "        x = x + self.layers[20](x)\n",
        "        x = x + self.layers[21](x)\n",
        "        x = x + self.layers[22](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[23](x)\n",
        "        x = self.layers[24](x)\n",
        "        x = self.layers[25](x)\n",
        "        \n",
        "        x = x + self.layers[26](x)\n",
        "        x = x + self.layers[27](x)\n",
        "        x = x + self.layers[28](x)\n",
        "        x = x + self.layers[29](x)\n",
        "        x = x + self.layers[30](x)\n",
        "        x = x + self.layers[31](x)\n",
        "        x = x + self.layers[32](x)\n",
        "        x = x + self.layers[33](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[34](x)\n",
        "        x = self.layers[35](x)\n",
        "        x = self.layers[36](x)\n",
        "        \n",
        "        x = x + self.layers[37](x)\n",
        "        x = x + self.layers[38](x)\n",
        "        x = x + self.layers[39](x)\n",
        "        x = x + self.layers[40](x)\n",
        "\n",
        "        x = self.layers[41](x)\n",
        "        x = self.layers[42](x)\n",
        "        x = self.layers[43](x)\n",
        "        \n",
        "        x = self.layers[44](x)\n",
        "        x = self.layers[45](x)\n",
        "        x = self.layers[46](x)\n",
        "\n",
        "        x = self.layers[47](x)\n",
        "        x = self.layers[48](x)\n",
        "        x = self.layers[49](x)\n",
        "        xx = self.layers[50](x)\n",
        "        x = self.layers[51](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[52](xx)\n",
        "        x = self.layers[53](x)\n",
        "        x = self.layers[54](x)\n",
        "        \n",
        "        x = self.layers[55](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[56](x)\n",
        "        x = self.layers[57](x)\n",
        "        x = self.layers[58](x)\n",
        "        \n",
        "        x = self.layers[59](x)\n",
        "        x = self.layers[60](x)\n",
        "        x = self.layers[61](x)\n",
        "        \n",
        "        x = self.layers[62](x)\n",
        "        x = self.layers[63](x)\n",
        "        x = self.layers[64](x)\n",
        "        xx = self.layers[65](x)\n",
        "        x = self.layers[66](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[67](xx)\n",
        "        x = self.layers[68](x)\n",
        "        x = self.layers[69](x)\n",
        "        \n",
        "        x = self.layers[70](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[71](x)\n",
        "        x = self.layers[72](x)\n",
        "        x = self.layers[73](x)\n",
        "        \n",
        "        x = self.layers[74](x)\n",
        "        x = self.layers[75](x)\n",
        "        x = self.layers[76](x)\n",
        "\n",
        "        x = self.layers[77](x)\n",
        "        x = self.layers[78](x)\n",
        "        x = self.layers[79](x)\n",
        "        xx = self.layers[80](x)\n",
        "        x = self.layers[81](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ucGNQgXnQt_"
      },
      "source": [
        "num_classes = 3\n",
        "IMAGE_SIZE = 224\n",
        "model = yolo_model()\n",
        "out = model.evaluateModel(x)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q-_GzEQFzZp",
        "outputId": "16df18ce-cf83-4643-cdd7-af1261884f32"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (2): LeakyReLU(negative_slope=0.1)\n",
              "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (5): LeakyReLU(negative_slope=0.1)\n",
              "  (6): Sequential(\n",
              "    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (9): LeakyReLU(negative_slope=0.1)\n",
              "  (10): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (11): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (13): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (14): LeakyReLU(negative_slope=0.1)\n",
              "  (15): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (16): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (17): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (18): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (19): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (20): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (21): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (22): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (23): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (24): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (25): LeakyReLU(negative_slope=0.1)\n",
              "  (26): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (27): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (28): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (29): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (30): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (31): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (32): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (33): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (34): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (35): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (36): LeakyReLU(negative_slope=0.1)\n",
              "  (37): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (38): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (39): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (40): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (41): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (42): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (43): LeakyReLU(negative_slope=0.1)\n",
              "  (44): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (45): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (46): LeakyReLU(negative_slope=0.1)\n",
              "  (47): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (48): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (50): LeakyReLU(negative_slope=0.1)\n",
              "  (51): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(1024, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (52): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (53): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (54): LeakyReLU(negative_slope=0.1)\n",
              "  (55): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (56): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (57): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (58): LeakyReLU(negative_slope=0.1)\n",
              "  (59): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (60): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (61): LeakyReLU(negative_slope=0.1)\n",
              "  (62): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (63): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (64): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (65): LeakyReLU(negative_slope=0.1)\n",
              "  (66): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (67): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (68): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (69): LeakyReLU(negative_slope=0.1)\n",
              "  (70): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (71): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (72): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (73): LeakyReLU(negative_slope=0.1)\n",
              "  (74): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (75): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (76): LeakyReLU(negative_slope=0.1)\n",
              "  (77): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (78): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (79): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (80): LeakyReLU(negative_slope=0.1)\n",
              "  (81): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8MOj1p-QiJg",
        "outputId": "673f61a9-af78-4f0f-97dd-27cac52fc743"
      },
      "source": [
        "out[0].shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 7, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRJOh-NBQu8W",
        "outputId": "f7cfe941-fe01-43be-d6ea-0f16fd79584c"
      },
      "source": [
        "out[1].shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 14, 14, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XCOItjTQxwq",
        "outputId": "2a7628fb-7275-49ec-ba82-12b4f1b97a4c"
      },
      "source": [
        "out[2].shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 28, 28, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}