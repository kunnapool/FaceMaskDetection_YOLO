{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQOkZrQzd-w"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ULGG1pFzgmO",
        "outputId": "2433b6b0-f427-4f30-fd6b-1b6c3c104ce5"
      },
      "source": [
        "!pip install xmltodict"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (0.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQobTGRNiG49",
        "outputId": "73dea514-f4ed-45ec-86db-9b4a33a48875"
      },
      "source": [
        "ls"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBsXpnp_FC-U",
        "outputId": "06b0a6aa-a54c-4611-9171-84e60dd5c541"
      },
      "source": [
        "!pip install --upgrade albumentations"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.5.3.56)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utg_rXwHhmbL",
        "outputId": "17516583-d416-4056-c2ae-dec78cee83a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msfe13Aazi3d"
      },
      "source": [
        "import xmltodict\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCUqRJUozkna",
        "outputId": "6f2af06d-69b7-42be-a8e9-9bc97d334b81"
      },
      "source": [
        "cd drive/MyDrive/SENG474/Project"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/SENG474/Project'\n",
            "/content/drive/My Drive/SENG474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ48tmDKPCYn"
      },
      "source": [
        "def resize_image_with_BB(image, width, height, list_BB):\n",
        "    h = image.shape[0]\n",
        "    w = image.shape[1]\n",
        "\n",
        "    new_size = (width, height)\n",
        "\n",
        "    new_BB_list = []\n",
        "\n",
        "    for i in range(len(list_BB)):\n",
        "\n",
        "        x1, y1, x2, y2, l = list_BB[i]\n",
        "\n",
        "        r_w = width/w\n",
        "        r_h = height/h\n",
        "\n",
        "        x1 *= r_w\n",
        "        x2 *= r_w\n",
        "\n",
        "        y1 *= r_h\n",
        "        y2 *= r_h\n",
        "\n",
        "        new_BB = (int(x1), int(y1), int(x2), int(y2), l)\n",
        "        new_BB_list.append(new_BB)\n",
        "\n",
        "    return cv2.resize(image, new_size, interpolation = cv2.INTER_AREA), new_BB_list"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r_DFMDwzmj1"
      },
      "source": [
        "images = []\n",
        "annotations = []\n",
        "\n",
        "image_dir = os.getcwd() + '/data/images'\n",
        "annot_dir = os.getcwd() + '/data/annotations'\n",
        "\n",
        "for filename in os.listdir(annot_dir):\n",
        "    annotations.append(filename)\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    images.append(filename)\n",
        "\n",
        "images = sorted(images)\n",
        "annotations = sorted(annotations)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNfPIeF0vDRT"
      },
      "source": [
        "class_ids = [0,1,2]\n",
        "class_names = {0:'without_mask', 1: 'with_mask', 2:'mask_weared_incorrect'}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esfp4hUrzpE4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "bboxes0 = []\n",
        "bboxes1 = []\n",
        "bboxes2 = []\n",
        "B0 = []\n",
        "B1 = []\n",
        "B2 = []\n",
        "dataimage = []\n",
        "classes = {'without_mask':0, 'with_mask':1, 'mask_weared_incorrect':2}\n",
        "\n",
        "for i in range (0,len(annotations)):\n",
        "    annot_file = open(os.path.join(annot_dir, annotations[i]), 'r')\n",
        "    image_filename = os.path.join(image_dir, images[i])\n",
        "\n",
        "    annot_data = annot_file.read()\n",
        "    annot_dict = xmltodict.parse(annot_data)['annotation']\n",
        "\n",
        "    image = cv2.imread(image_filename)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    objects = annot_dict['object']\n",
        "    B = []\n",
        "    if isinstance(objects, list):\n",
        "        for item in objects:\n",
        "          xmin = int(item['bndbox']['xmin'])\n",
        "          ymin = int(item['bndbox']['ymin'])\n",
        "          xmax = int(item['bndbox']['xmax'])\n",
        "          ymax = int(item['bndbox']['ymax'])\n",
        "          label = classes[item['name']] # 1-hot encoding.\n",
        "\n",
        "          bbox = (xmin, ymin, xmax, ymax, label)\n",
        "          B0.append(bbox)\n",
        "          B1.append(bbox)\n",
        "          B2.append(bbox)\n",
        "    else:\n",
        "        xmin = int(item['bndbox']['xmin'])\n",
        "        ymin = int(item['bndbox']['ymin'])\n",
        "        xmax = int(item['bndbox']['xmax'])\n",
        "        ymax = int(item['bndbox']['ymax'])\n",
        "        label = classes[item['name']] # 1-hot encoding.\n",
        "\n",
        "        bbox = (xmin, ymin, xmax, ymax, label)\n",
        "        B0.append(bbox)\n",
        "        B1.append(bbox)\n",
        "        B2.append(bbox)\n",
        "\n",
        "    image, B0 = resize_image_with_BB(image, 416, 416, B0)\n",
        "    _, B1 = resize_image_with_BB(image, 32, 32, B1)\n",
        "    _, B2 = resize_image_with_BB(image, 16, 16, B2)\n",
        "\n",
        "    dataimage.append(image)\n",
        "    bboxes0.append(B0)\n",
        "    bboxes1.append(B1)\n",
        "    bboxes2.append(B2)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEPDfo2szsu9"
      },
      "source": [
        "x = torch.from_numpy(dataimage[0])\n",
        "x = torch.unsqueeze(x, -1)\n",
        "x = x.reshape((1,3,x.shape[0], x.shape[1]))\n",
        "x = x.float()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVUpJgk6rqj3",
        "outputId": "b9e0b702-eaff-4b6e-e082-9d11dab2d053"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 416, 416])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0-x0H1oRIG"
      },
      "source": [
        "config = [\n",
        "  \n",
        "    (32, 3, 1),\n",
        "    (64, 3, 2),\n",
        "    [\"B\", 1],\n",
        "    (128, 3, 2),\n",
        "    [\"B\", 2],\n",
        "    (256, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (512, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (1024, 3, 2),\n",
        "    [\"B\", 4],  # To this point is Darknet-53\n",
        "    (512, 1, 1),\n",
        "    (1024, 3, 1),\n",
        "    \"S\",\n",
        "    (256, 1, 1),\n",
        "    \"U\",\n",
        "    (256, 1, 1),\n",
        "    (512, 3, 1),\n",
        "    \"S\",\n",
        "    (128, 1, 1),\n",
        "    \"U\",\n",
        "    (128, 1, 1),\n",
        "    (256, 3, 1),\n",
        "    \"S\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6QUUz3Bzymn"
      },
      "source": [
        "# Hyperparameters\n",
        "leakyReLuAlpha = 0.1\n",
        "bn_momentum = 0.999"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZEjRIB4z1HU"
      },
      "source": [
        "class yolo_model(nn.Module):\n",
        "\n",
        "    def __init__(self, leakyReLuAlpha = 0.1, bn_momentum = 0.999):\n",
        "        super(yolo_model, self).__init__()\n",
        "        self.leakyReLuAlpha = leakyReLuAlpha\n",
        "        self.usebias = True\n",
        "        self.bn_momentum = bn_momentum\n",
        "        self.layers = self.createModelLayers()\n",
        "\n",
        "    def createModelLayers(self):\n",
        "        layers = nn.ModuleList()\n",
        "\n",
        "        ''' convs '''\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(3, 32, 3, 1, bias= self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(32, 64, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' residual '''\n",
        "        layer1a = nn.Conv2d(64, 32, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(32, 64, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "        layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(64, 128, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 2 resiudal repeats '''\n",
        "        layer1a = nn.Conv2d(128, 64, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(64, 128, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(128, 256, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1a = nn.Conv2d(256, 128, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(128, 256, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,8):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 512, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1a = nn.Conv2d(512, 256, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(256, 512, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,8):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 1024, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 4 residual repeats '''\n",
        "        layer1a = nn.Conv2d(1024, 512, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "      \n",
        "        layer2a = nn.Conv2d(512, 1024, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,4):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(1024, 512, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(512, 1024, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(1024, 512, kernel_size=1, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(0.1)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size= 3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer,)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(768, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(256, 512, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(512, 256, kernel_size=1, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(0.1)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size= 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(384, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(128, 256, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(256, 128, kernel_size=1, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(0.1)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size= 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        return layers\n",
        "\n",
        "    def evaluateModel(self, inputtensor):\n",
        "        route = []\n",
        "        output = []\n",
        "        x = self.layers[0](inputtensor)\n",
        "        x = self.layers[1](x)\n",
        "        x = self.layers[2](x)\n",
        "        \n",
        "        x = self.layers[3](x)\n",
        "        x = self.layers[4](x)\n",
        "        x = self.layers[5](x)\n",
        "        \n",
        "        x = x + self.layers[6](x)\n",
        "        \n",
        "        x = self.layers[7](x)\n",
        "        x = self.layers[8](x)\n",
        "        x = self.layers[9](x)\n",
        "\n",
        "        x = x + self.layers[10](x)\n",
        "        x = x + self.layers[11](x)\n",
        "        \n",
        "        x = self.layers[12](x)\n",
        "        x = self.layers[13](x)\n",
        "        x = self.layers[14](x)\n",
        "        \n",
        "        x = x + self.layers[15](x)\n",
        "        x = x + self.layers[16](x)\n",
        "        x = x + self.layers[17](x)\n",
        "        x = x + self.layers[18](x)\n",
        "        x = x + self.layers[19](x)\n",
        "        x = x + self.layers[20](x)\n",
        "        x = x + self.layers[21](x)\n",
        "        x = x + self.layers[22](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[23](x)\n",
        "        x = self.layers[24](x)\n",
        "        x = self.layers[25](x)\n",
        "        \n",
        "        x = x + self.layers[26](x)\n",
        "        x = x + self.layers[27](x)\n",
        "        x = x + self.layers[28](x)\n",
        "        x = x + self.layers[29](x)\n",
        "        x = x + self.layers[30](x)\n",
        "        x = x + self.layers[31](x)\n",
        "        x = x + self.layers[32](x)\n",
        "        x = x + self.layers[33](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[34](x)\n",
        "        x = self.layers[35](x)\n",
        "        x = self.layers[36](x)\n",
        "        \n",
        "        x = x + self.layers[37](x)\n",
        "        x = x + self.layers[38](x)\n",
        "        x = x + self.layers[39](x)\n",
        "        x = x + self.layers[40](x)\n",
        "\n",
        "        x = self.layers[41](x)\n",
        "        x = self.layers[42](x)\n",
        "        x = self.layers[43](x)\n",
        "        \n",
        "        x = self.layers[44](x)\n",
        "        x = self.layers[45](x)\n",
        "        x = self.layers[46](x)\n",
        "\n",
        "        x = self.layers[47](x)\n",
        "        x = self.layers[48](x)\n",
        "        x = self.layers[49](x)\n",
        "        xx = self.layers[50](x)\n",
        "        x = self.layers[51](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[52](xx)\n",
        "        x = self.layers[53](x)\n",
        "        x = self.layers[54](x)\n",
        "        \n",
        "        x = self.layers[55](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[56](x)\n",
        "        x = self.layers[57](x)\n",
        "        x = self.layers[58](x)\n",
        "        \n",
        "        x = self.layers[59](x)\n",
        "        x = self.layers[60](x)\n",
        "        x = self.layers[61](x)\n",
        "        \n",
        "        x = self.layers[62](x)\n",
        "        x = self.layers[63](x)\n",
        "        x = self.layers[64](x)\n",
        "        xx = self.layers[65](x)\n",
        "        x = self.layers[66](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[67](xx)\n",
        "        x = self.layers[68](x)\n",
        "        x = self.layers[69](x)\n",
        "        \n",
        "        x = self.layers[70](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[71](x)\n",
        "        x = self.layers[72](x)\n",
        "        x = self.layers[73](x)\n",
        "        \n",
        "        x = self.layers[74](x)\n",
        "        x = self.layers[75](x)\n",
        "        x = self.layers[76](x)\n",
        "\n",
        "        x = self.layers[77](x)\n",
        "        x = self.layers[78](x)\n",
        "        x = self.layers[79](x)\n",
        "        xx = self.layers[80](x)\n",
        "        x = self.layers[81](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ucGNQgXnQt_"
      },
      "source": [
        "num_classes = 3\n",
        "IMAGE_SIZE = 224\n",
        "model = yolo_model()\n",
        "out = model.evaluateModel(x)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q-_GzEQFzZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3713d8-3b0a-4728-c605-f678f9672518"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (2): LeakyReLU(negative_slope=0.1)\n",
              "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (5): LeakyReLU(negative_slope=0.1)\n",
              "  (6): Sequential(\n",
              "    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (9): LeakyReLU(negative_slope=0.1)\n",
              "  (10): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (11): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (13): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (14): LeakyReLU(negative_slope=0.1)\n",
              "  (15): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (16): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (17): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (18): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (19): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (20): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (21): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (22): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (23): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (24): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (25): LeakyReLU(negative_slope=0.1)\n",
              "  (26): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (27): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (28): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (29): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (30): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (31): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (32): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (33): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (34): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (35): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (36): LeakyReLU(negative_slope=0.1)\n",
              "  (37): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (38): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (39): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (40): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (41): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (42): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (43): LeakyReLU(negative_slope=0.1)\n",
              "  (44): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (45): BatchNorm2d(1024, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (46): LeakyReLU(negative_slope=0.1)\n",
              "  (47): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (48): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (50): LeakyReLU(negative_slope=0.1)\n",
              "  (51): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(1024, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (52): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (53): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (54): LeakyReLU(negative_slope=0.1)\n",
              "  (55): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (56): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (57): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (58): LeakyReLU(negative_slope=0.1)\n",
              "  (59): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (60): BatchNorm2d(512, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (61): LeakyReLU(negative_slope=0.1)\n",
              "  (62): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (63): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (64): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (65): LeakyReLU(negative_slope=0.1)\n",
              "  (66): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (67): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (68): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (69): LeakyReLU(negative_slope=0.1)\n",
              "  (70): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (71): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (72): BatchNorm2d(128, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (73): LeakyReLU(negative_slope=0.1)\n",
              "  (74): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (75): BatchNorm2d(256, eps=1e-05, momentum=0.999, affine=True, track_running_stats=True)\n",
              "  (76): LeakyReLU(negative_slope=0.1)\n",
              "  (77): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (78): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (79): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (80): LeakyReLU(negative_slope=0.1)\n",
              "  (81): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1vrQ0Zxa1mi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcLRSuKYbBhG"
      },
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "def iou(b1, b2, is_midpt=False):\n",
        "    \"\"\"\n",
        "    :params: b1 is the first bounding box - b1 = (x1, y1, x2, y2)\n",
        "    :params: b2 is the second bounding box\n",
        "    :return: The intersection over union area of b1 and b2\n",
        "    \"\"\"\n",
        "\n",
        "    if is_midpt:\n",
        "        b1, b2 = get_box_cords_from_midpt(b1, b2)\n",
        "\n",
        "    b1_x1, b1_y1, b1_x2, b1_y2 = b1\n",
        "    b2_x1, b2_y1, b2_x2, b2_y2 = b2\n",
        "\n",
        "\n",
        "    # the following 4 points (i_ ) represent the intersection box\n",
        "    i_x1 = max(b1_x1, b2_x1)\n",
        "    i_y1 = max(b1_y1, b2_y1)\n",
        "\n",
        "    i_x2 = min(b1_x2, b2_x2)\n",
        "    i_y2 = min(b1_y2, b2_y2)\n",
        "\n",
        "    i_area = abs(i_x1 - i_x2) * abs(i_y1 - i_y2)\n",
        "\n",
        "    u_area = abs(b1_x1 - b1_x2) * abs(b1_y1 - b1_y2) + \\\n",
        "             abs(b2_x1 - b2_x2) * abs(b2_y1 - b2_y2)\n",
        "\n",
        "\n",
        "    return i_area/u_area\n",
        "\n",
        "\n",
        "def get_box_cords_from_midpt(b1, b2):\n",
        "    xm1, ym1, w1, h1 = b1\n",
        "    xm2, ym2, w2, h2 = b2\n",
        "\n",
        "    b1_x1 = xm1 - w1/2\n",
        "    b1_y1 = ym1 - h1/2\n",
        "    b1_x2 = xm1 + w1/2\n",
        "    b1_y2 = ym1 + h1/2\n",
        "\n",
        "    b2_x1 = xm2 - w2/2\n",
        "    b2_y1 = ym2 - h2/2\n",
        "    b2_x2 = xm2 + w2/2\n",
        "    b2_y2 = ym2 + h2/2\n",
        "    \n",
        "\n",
        "    return (b1_x1, b1_y1, b1_x2, b1_y2), (b2_x1, b2_y1, b2_x2, b2_y2)\n",
        "\n",
        "def nonmax_sup(b1, b2, b1_p, b2_p, is_midpt=False, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Non-max suppression for bounding boxes.\n",
        "    Function calculates IOU, and if the value if above the threshold, rejects the\n",
        "    box with lower probability\n",
        "\n",
        "    :return: -1 indicates the lower probability box should be rejected\n",
        "              0 means it should be kept\n",
        "    \"\"\"\n",
        "    max_p = max(b1_p, b2_p)\n",
        "    iou = iou(b1, b2, is_midpt)\n",
        "\n",
        "    if iou > iou_threshold:\n",
        "        return -1\n",
        "    \n",
        "    return 0\n",
        "\n",
        "\n",
        "def resize_image_with_BB(image, width, height, list_BB):\n",
        "    h = image.shape[0]\n",
        "    w = image.shape[1]\n",
        "\n",
        "    new_size = (width, height)\n",
        "\n",
        "    new_BB_list = []\n",
        "\n",
        "    for i in range(len(list_BB)):\n",
        "\n",
        "        x1, y1, x2, y2, l = list_BB[i]\n",
        "\n",
        "        r_w = width/w\n",
        "        r_h = height/h\n",
        "\n",
        "\n",
        "        x1 *= r_w\n",
        "        x2 *= r_w\n",
        "\n",
        "        y1 *= r_h\n",
        "        y2 *= r_h\n",
        "\n",
        "        new_BB = (int(x1), int(y1), int(x2), int(y2), l)\n",
        "\n",
        "        new_BB_list.append(new_BB)\n",
        "\n",
        "    return cv2.resize(image, new_size, interpolation = cv2.INTER_AREA), new_BB_list"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLK3E7cUCssA"
      },
      "source": [
        "def _get_grid_BBs(target, S=13):\n",
        "    \"\"\"\n",
        "    The incoming target variable is a list of all the\n",
        "    BBs present in an image\n",
        "    Assume that the image is divided into SxS grids and figure out of\n",
        "    which grid does the BB land in\n",
        "    \"\"\"\n",
        "\n",
        "    grid_target = -1*np.ones((S, S, 5))\n",
        "\n",
        "    for b in target:\n",
        "        x1, y1, x2, y2, l = b\n",
        "        mid_x = abs(x1 - x2)/2\n",
        "        mid_y = abs(y1 - y2)/2\n",
        "\n",
        "        s1 = min(int(mid_y/S), S-1)\n",
        "        s2 = min(int(mid_x/S), S-1)\n",
        "\n",
        "        grid_target[s1, s2] = [x1, y1, x2, y2, l]\n",
        "\n",
        "    return grid_target\n",
        "\n",
        "def _get_softmax(x):\n",
        "    l = []\n",
        "    s = 0\n",
        "    for xi in x:\n",
        "        s += math.e**xi\n",
        "    \n",
        "    for xi in x:\n",
        "        l.append(xi/s)\n",
        "\n",
        "    return l\n",
        "\n",
        "\n",
        "def loss(pred, target, B=2, S=13):\n",
        "    \"\"\"\n",
        "    The pred size should be (SxSx(B*E + C))\n",
        "        S - grid size\n",
        "        B - Number of bounding boxes (number of predictions) per grid cell\n",
        "        E - Number of elements predicted per box\n",
        "        C - Number of classes\n",
        "    Format of predicted elements, E - [x1, y1, w1, h1, conf1, x2... conf_n, class_probs]\n",
        "        x, y - center point of the BB relative to the grid cell; relative range of [0, 1]\n",
        "        w, h - width, height of the BB relative to the image; relative range of [0, 1]\n",
        "        conf - Defined as Pr(obj) * IOU(pred, truth)\n",
        "               0 if no obj\n",
        "    \"\"\"\n",
        "\n",
        "    def get_best_box(arr, t_bb):\n",
        "        st = 0\n",
        "        end = 5\n",
        "        max_bb = []\n",
        "        max_iou = -1\n",
        "        best_conf = -1 # confidence of the best box\n",
        "\n",
        "        # get the BB with the box prob\n",
        "        for b in range(B):\n",
        "            x1, y1, x2, y2, conf = arr[st: end]\n",
        "            st = end\n",
        "            end += 5\n",
        "\n",
        "            bb = [x1, y1, x2, y2]\n",
        "            i = iou(bb, t_bb)\n",
        "\n",
        "            if i > max_iou:\n",
        "                max_bb = bb\n",
        "                max_iou = i\n",
        "                best_conf = conf\n",
        "\n",
        "        return max_bb, max_iou, best_conf\n",
        "\n",
        "    lmbda = 0.5\n",
        "\n",
        "    target = _get_grid_BBs(target, S)\n",
        "\n",
        "    loss_1 = 0 # TODO Also update these names\n",
        "    loss_2 = 0\n",
        "    loss_3 = 0\n",
        "    loss_4 = 0\n",
        "\n",
        "    # iterate over each grid (per image)\n",
        "    for s1 in range(S):\n",
        "        for s2 in range(S):    \n",
        "            # this should have B instances of [x1, y1, x2, y2, label] # TODO Update this\n",
        "            # and then class probabilites\n",
        "\n",
        "            arr = pred[s1, s2]\n",
        "            arr2 = target[s1, s2]\n",
        "            x1, y1, x2, y2, gd_label = arr2\n",
        "            t_bb = [x1, y1, x2, y2]\n",
        "\n",
        "            # TODO check if there are any boxes at all\n",
        "            # TODO_UPDATE - this might not be needed as every grid predicts B number of BBs\n",
        "            best_bb, best_iou, pred_conf = get_best_box(arr, t_bb)\n",
        "\n",
        "            x1, y1, x2, y2 = best_bb\n",
        "\n",
        "            # The BB with the highest IOU (with the GD) will be the box responsible\n",
        "            # for detecting\n",
        "\n",
        "            if gd_label != -1:\n",
        "                loss_1 += (x1 - t_bb[0])**2 + \\\n",
        "                    (x2 - t_bb[2])**2 + \\\n",
        "                    (y1 - t_bb[1])**2 + \\\n",
        "                    (y2 - t_bb[3])**2\n",
        "\n",
        "            bb_h = abs(y1 - y2)\n",
        "            bb_w = abs(x1 - x2)\n",
        "\n",
        "            t_bb_h = abs(t_bb[1] - t_bb[3])\n",
        "            t_bb_w = abs(t_bb[0] - t_bb[2])\n",
        "\n",
        "            if gd_label != -1:\n",
        "                loss_2 += (math.sqrt(bb_h) - math.sqrt(t_bb_h))**2 + \\\n",
        "                    (math.sqrt(bb_w) - math.sqrt(t_bb_w))**2\n",
        "            \n",
        "            if gd_label != -1:\n",
        "                a = [float(x) for x in arr[5*B:]]\n",
        "                pred_class_probs = _get_softmax(a)\n",
        "\n",
        "                # -1 because all the probability goes to the gd label\n",
        "                if pred_class_probs[int(gd_label)] > 0:\n",
        "                  loss_4 += -1 * math.log(pred_class_probs[int(gd_label)])\n",
        "\n",
        "\n",
        "    return (loss_1 + loss_2 + loss_3 + loss_4)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEnwAsn-Ixcd"
      },
      "source": [
        "import math\n",
        "\n",
        "num_classes = 3\n",
        "model = yolo_model()\n",
        "\n",
        "epochs = 3\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "train_dataimages = dataimage[:500]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  num_iter = 0\n",
        "  cnt = 0\n",
        "  for image in train_dataimages:\n",
        "    if num_iter % 50 == 0:\n",
        "      print(\"Iteration number: \", num_iter)\n",
        "    try:\n",
        "      x = torch.from_numpy(image)\n",
        "      x = torch.unsqueeze(x, -1)\n",
        "      x = x.reshape((1,3,x.shape[0], x.shape[1]))\n",
        "      x = x.float()\n",
        "      out = model.evaluateModel(x)\n",
        "      l = loss(out[0][0][0], bboxes0[cnt], B=1, S=13) + loss(out[1][0][0], bboxes1[cnt], B=1, S=26) + loss(out[2][0][0], bboxes2[cnt], B=1, S=52)\n",
        "      loss_list.append(l)\n",
        "  \n",
        "      optim.zero_grad()\n",
        "      l.backward()\n",
        "      optim.step()\n",
        "      cnt +=1\n",
        "      num_iter += 1\n",
        "    except Exception as e:\n",
        "      print(\"An Error occurred\")\n",
        "      continue\n",
        "\n",
        "  print(\"Epoch done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jDA0xorpTKt_",
        "outputId": "51cf99c9-ac4a-4328-8ac9-ed8b1aef771f"
      },
      "source": [
        "plt.plot(loss_list)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feefb2c5b10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiTY6fpKiEOs",
        "outputId": "8d5fe28b-55f9-4258-c639-eb2fa5675085"
      },
      "source": [
        "min(loss_list)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(327574.2500, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QVuuyTBjlxh",
        "outputId": "b0d8a3d5-3817-4297-c5a6-943358387851"
      },
      "source": [
        ""
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}