{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "updatedProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQOkZrQzd-w"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ULGG1pFzgmO",
        "outputId": "9caeb1c8-28ae-47b0-bbd1-610c18ffce1c"
      },
      "source": [
        "pip install xmltodict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msfe13Aazi3d"
      },
      "source": [
        "import xmltodict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCUqRJUozkna",
        "outputId": "8e93d72f-1909-4b59-fbdf-d13d61c275f0"
      },
      "source": [
        "cd drive/MyDrive/CSC474/Project"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSC474/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r_DFMDwzmj1"
      },
      "source": [
        "images = []\n",
        "annotations = []\n",
        "\n",
        "image_dir = os.getcwd() + '/data/images'\n",
        "annot_dir = os.getcwd() + '/data/annotations'\n",
        "\n",
        "for filename in os.listdir(annot_dir):\n",
        "    annotations.append(filename)\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    images.append(filename)\n",
        "\n",
        "images = sorted(images)\n",
        "annotations = sorted(annotations)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esfp4hUrzpE4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "bboxes = []\n",
        "dataimage = []\n",
        "classes = {'without_mask':0, 'with_mask':1, 'mask_weared_incorrect':2}\n",
        "\n",
        "for i in range (0,len(annotations)):\n",
        "    annot_file = open(os.path.join(annot_dir, annotations[i]), 'r')\n",
        "    image_filename = os.path.join(image_dir, images[i])\n",
        "\n",
        "    annot_data = annot_file.read()\n",
        "    annot_dict = xmltodict.parse(annot_data)['annotation']\n",
        "\n",
        "    image = Image.open(image_filename)\n",
        "\n",
        "    objects = annot_dict['object']\n",
        "    if isinstance(objects, list):\n",
        "        for item in objects:\n",
        "          xmin = int(item['bndbox']['xmin'])\n",
        "          ymin = int(item['bndbox']['ymin'])\n",
        "          xmax = int(item['bndbox']['xmax'])\n",
        "          ymax = int(item['bndbox']['ymax'])\n",
        "          label = classes[item['name']] # 1-hot encoding.\n",
        "\n",
        "          bbox = (xmin, ymin, xmax, ymax, label)\n",
        "          bboxes.append(bbox)\n",
        "  \n",
        "          image = image.resize((224,224), Image.ANTIALIAS)\n",
        "          image = image.convert(mode='RGB')\n",
        "          image_arr = img_to_array(image)\n",
        "          dataimage.append(image_arr)\n",
        "\n",
        "    else:\n",
        "        xmin = int(item['bndbox']['xmin'])\n",
        "        ymin = int(item['bndbox']['ymin'])\n",
        "        xmax = int(item['bndbox']['xmax'])\n",
        "        ymax = int(item['bndbox']['ymax'])\n",
        "        label = classes[item['name']] # 1-hot encoding.\n",
        "\n",
        "        bbox = (xmin, ymin, xmax, ymax, label)\n",
        "        bboxes.append(bbox)\n",
        "  \n",
        "        image = image.resize((224,224), Image.ANTIALIAS)\n",
        "        image = image.convert(mode='RGB')\n",
        "        image_arr = img_to_array(image)\n",
        "        dataimage.append(image_arr)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEPDfo2szsu9"
      },
      "source": [
        "x = torch.from_numpy(np.array(dataimage))\n",
        "x = torch.unsqueeze(x, -1)\n",
        "x = x[0].reshape((1,3,224,224))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJnpfOZ5zv7z"
      },
      "source": [
        "config = [\n",
        "    (32, 3, 1),\n",
        "    (64, 3, 2),\n",
        "    [\"B\", 1],\n",
        "    (128, 3, 2),\n",
        "    [\"B\", 2],\n",
        "    (256, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (512, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (1024, 3, 2),\n",
        "    [\"B\", 4],  # To this point is Darknet-53\n",
        "    (512, 1, 1),\n",
        "    (1024, 3, 1),\n",
        "    \"S\",\n",
        "    (256, 1, 1),\n",
        "    \"U\",\n",
        "    (256, 1, 1),\n",
        "    (512, 3, 1),\n",
        "    \"S\",\n",
        "    (128, 1, 1),\n",
        "    \"U\",\n",
        "    (128, 1, 1),\n",
        "    (256, 3, 1),\n",
        "    \"S\",\n",
        "]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6QUUz3Bzymn"
      },
      "source": [
        "# Hyperparameters\n",
        "leakyReLuAlpha = 0.1\n",
        "bn_momentum = 0.999\n",
        "conv_bias = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZEjRIB4z1HU"
      },
      "source": [
        "class yolo_model(nn.Module):\n",
        "\n",
        "    def __init__(self, leakyReLuAlpha = 0.1, bn_momentum = 0.999, usebias = False):\n",
        "        super(yolo_model, self).__init__()\n",
        "        self.leakyReLuAlpha = leakyReLuAlpha\n",
        "        self.bn_momentum = bn_momentum\n",
        "        self.usebias = usebias\n",
        "        self.layers = self.createModelLayers()\n",
        "\n",
        "    def createModelLayers(self):\n",
        "        layers = nn.ModuleList()\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(3, 32, 3, 1, bias= self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(32, 64, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' residual '''\n",
        "        layer1a = nn.Conv2d(64, 32, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(32, 64, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "        layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(64, 128, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 2 resiudal repeats '''\n",
        "        layer1a = nn.Conv2d(128, 64, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(64, 128, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(128, 256, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1a = nn.Conv2d(256, 128, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(128, 256, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 512, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1a = nn.Conv2d(512, 256, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2a = nn.Conv2d(256, 512, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 1024, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 4 residual repeats '''\n",
        "        layer1a = nn.Conv2d(1024, 512, 1, bias = self.usebias, padding=0)\n",
        "        layer1b = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer1c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "      \n",
        "        layer2a = nn.Conv2d(512, 1024, 3, bias= self.usebias, padding=1)\n",
        "        layer2b = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layer2c = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1a,layer1b,layer1c,layer2a,layer2b,layer2c)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(1024, 512, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(512, 1024, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3),\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(1024, 512, kernel_size=1, padding=0)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size= 3, padding=1),\n",
        "            nn.BatchNorm2d(1024)\n",
        "            nn.LeakyReLU(0.1)\n",
        "            nn.Conv2d(1024, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(768, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(256, 512, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3),\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        layer = nn.Conv2d(512, 256, kernel_size=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size= 3, padding=1),\n",
        "            nn.Conv2d(512, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(384, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(128, 256, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=1),\n",
        "            nn.Conv2d(128, 256, kernel_size=3),\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        layer = nn.Conv2d(256, 128, kernel_size=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size= 3, padding=1),\n",
        "            nn.Conv2d(256, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        return layers\n",
        "\n",
        "    def evaluateModel(self, inputtensor):\n",
        "        route = []\n",
        "        output = []\n",
        "        x = self.layers[0](inputtensor)\n",
        "        print(x.shape)\n",
        "        x = self.layers[1](x)\n",
        "        print(x.shape)\n",
        "        x = self.layers[2](x)\n",
        "        print(x.shape)\n",
        "        \n",
        "        x = self.layers[3](x)\n",
        "        print(x.shape)\n",
        "        x = self.layers[4](x)\n",
        "        print(x.shape)\n",
        "        x = self.layers[5](x)\n",
        "        print(x.shape)\n",
        "        \n",
        "        xx = self.layers[6](x)\n",
        "        x = x + xx\n",
        "        print(x.shape)\n",
        "        \n",
        "        x = self.layers[7](x)\n",
        "        print(x.shape)\n",
        "        x = self.layers[8](x)\n",
        "        print(x.shape)\n",
        "        x = self.layers[9](x)\n",
        "        print(x.shape)\n",
        "\n",
        "        x = x +self.layers[10](x)\n",
        "        x = x +self.layers[11](x)\n",
        "        \n",
        "        x = self.layers[12](x)\n",
        "        x = self.layers[13](x)\n",
        "        x = self.layers[14](x)\n",
        "        \n",
        "        x = x + self.layers[15](x)\n",
        "        print(x.shape)\n",
        "        x = x + self.layers[16](x)\n",
        "        print(x.shape)\n",
        "        x = x + self.layers[17](x)\n",
        "        print(x.shape)\n",
        "        x = x + self.layers[18](x)\n",
        "        x = x + self.layers[19](x)\n",
        "        x = x + self.layers[20](x)\n",
        "        x = x + self.layers[21](x)\n",
        "        x = x + self.layers[22](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[23](x)\n",
        "        x = self.layers[24](x)\n",
        "        x = self.layers[25](x)\n",
        "        \n",
        "        x = x + self.layers[26](x)\n",
        "        x = x + self.layers[27](x)\n",
        "        x = x + self.layers[28](x)\n",
        "        x = x + self.layers[29](x)\n",
        "        x = x + self.layers[30](x)\n",
        "        x = x + self.layers[31](x)\n",
        "        x = x + self.layers[32](x)\n",
        "        x = x + self.layers[33](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        print(x.shape)\n",
        "        x = self.layers[34](x)\n",
        "        print(x.shape)\n",
        "        x = self.layers[35](x)\n",
        "        print(x.shape)\n",
        "        x = self.layers[36](x)\n",
        "        print(x.shape)\n",
        "        \n",
        "        x = x + self.layers[37](x)\n",
        "        x = x + self.layers[38](x)\n",
        "        x = x + self.layers[39](x)\n",
        "        x = x + self.layers[40](x)\n",
        "\n",
        "        x = self.layers[41](x)\n",
        "        x = self.layers[42](x)\n",
        "        x = self.layers[43](x)\n",
        "        \n",
        "        x = self.layers[44](x)\n",
        "        x = self.layers[45](x)\n",
        "        x = self.layers[46](x)\n",
        "\n",
        "        x = self.layers[47](x)\n",
        "        xx = self.layers[48](x)\n",
        "        x = self.layers[49](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[50](xx)\n",
        "        x = self.layers[51](x)\n",
        "        x = self.layers[52](x)\n",
        "        \n",
        "        x = self.layers[53](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[54](x)\n",
        "        x = self.layers[55](x)\n",
        "        x = self.layers[56](x)\n",
        "        \n",
        "        x = self.layers[57](x)\n",
        "        x = self.layers[58](x)\n",
        "        x = self.layers[59](x)\n",
        "        \n",
        "        x = self.layers[60](x)\n",
        "        xx = self.layers[61](x)\n",
        "        x = self.layers[62](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[63](xx)\n",
        "        x = self.layers[64](x)\n",
        "        x = self.layers[65](x)\n",
        "        \n",
        "        x = self.layers[66](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[67](x)\n",
        "        x = self.layers[68](x)\n",
        "        x = self.layers[69](x)\n",
        "        \n",
        "        x = self.layers[70](x)\n",
        "        x = self.layers[71](x)\n",
        "        x = self.layers[72](x)\n",
        "\n",
        "        x = self.layers[73](x)\n",
        "        xx = self.layers[74](x)\n",
        "        x = self.layers[75](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "-ucGNQgXnQt_",
        "outputId": "30c4193d-69ea-494e-99e1-36d9cd32e2b8"
      },
      "source": [
        "num_classes = 3\n",
        "IMAGE_SIZE = 224\n",
        "model = yolo_model()\n",
        "out = model.evaluateModel(x)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32, 224, 224])\n",
            "torch.Size([1, 32, 224, 224])\n",
            "torch.Size([1, 32, 224, 224])\n",
            "torch.Size([1, 64, 112, 112])\n",
            "torch.Size([1, 64, 112, 112])\n",
            "torch.Size([1, 64, 112, 112])\n",
            "torch.Size([1, 64, 112, 112])\n",
            "torch.Size([1, 128, 56, 56])\n",
            "torch.Size([1, 128, 56, 56])\n",
            "torch.Size([1, 128, 56, 56])\n",
            "torch.Size([1, 256, 28, 28])\n",
            "torch.Size([1, 256, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-581ec3e01114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-8650a6384d50>\u001b[0m in \u001b[0;36mevaluateModel\u001b[0;34m(self, inputtensor)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (14) at non-singleton dimension 3"
          ]
        }
      ]
    }
  ]
}
