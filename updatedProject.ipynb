{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "updatedProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQOkZrQzd-w"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ULGG1pFzgmO",
        "outputId": "e37e2c79-504c-482d-8e07-a4dcd5da9f77"
      },
      "source": [
        "pip install xmltodict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msfe13Aazi3d"
      },
      "source": [
        "import xmltodict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCUqRJUozkna",
        "outputId": "1dc3394b-b1d6-4788-dc97-aca7de968dab"
      },
      "source": [
        "cd drive/MyDrive/CSC474/Project"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSC474/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r_DFMDwzmj1"
      },
      "source": [
        "images = []\n",
        "annotations = []\n",
        "\n",
        "image_dir = os.getcwd() + '/data/images'\n",
        "annot_dir = os.getcwd() + '/data/annotations'\n",
        "\n",
        "for filename in os.listdir(annot_dir):\n",
        "    annotations.append(filename)\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    images.append(filename)\n",
        "\n",
        "images = sorted(images)\n",
        "annotations = sorted(annotations)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esfp4hUrzpE4"
      },
      "source": [
        "faces = []\n",
        "labels = []\n",
        "classes = {'without_mask':0, 'with_mask':1, 'mask_weared_incorrect':2}\n",
        "\n",
        "for i in range (0,len(annotations)):\n",
        "  annot_file = open(os.path.join(annot_dir, annotations[i]), 'r')\n",
        "  image_filename = os.path.join(image_dir, images[i])\n",
        "\n",
        "  annot_data = annot_file.read()\n",
        "  annot_dict = xmltodict.parse(annot_data)['annotation']\n",
        "\n",
        "  image = Image.open(image_filename)\n",
        "\n",
        "  objects = annot_dict['object']\n",
        "  if isinstance(objects, list):\n",
        "      for item in objects:\n",
        "        xmin = int(item['bndbox']['xmin'])\n",
        "        ymin = int(item['bndbox']['ymin'])\n",
        "        xmax = int(item['bndbox']['xmax'])\n",
        "        ymax = int(item['bndbox']['ymax'])\n",
        "\n",
        "        faceRectangle = (xmin, ymin, xmax, ymax)\n",
        "        faceImage = image.crop(faceRectangle)\n",
        "        faceImage = faceImage.resize((224,224), Image.ANTIALIAS)\n",
        "        faceImage = faceImage.convert(mode='RGB')\n",
        "\n",
        "        faces.append(faceImage)\n",
        "        label = classes[item['name']] # 1-hot encoding.\n",
        "        labels.append(label)\n",
        "  else:\n",
        "      xmin = int(item['bndbox']['xmin'])\n",
        "      ymin = int(item['bndbox']['ymin'])\n",
        "      xmax = int(item['bndbox']['xmax'])\n",
        "      ymax = int(item['bndbox']['ymax'])\n",
        "\n",
        "      faceRectangle = (xmin, ymin, xmax, ymax)\n",
        "      faceImage = image.crop(faceRectangle)\n",
        "      faceImage = faceImage.resize((224,224), Image.ANTIALIAS)\n",
        "      faceImage = faceImage.convert(mode='RGB')\n",
        "\n",
        "      faces.append(faceImage)\n",
        "      label = classes[item['name']] # 1-hot encoding.\n",
        "      labels.append(label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEPDfo2szsu9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "faceImageArray = np.empty((len(faces), 224, 224, 3), dtype= int)\n",
        "for i in range(0, len(faces)):\n",
        "  faceImageArray[i] = img_to_array(faces[i])\n",
        "\n",
        "labels = np.array(labels)\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(faceImageArray, labels,test_size=0.20, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJnpfOZ5zv7z"
      },
      "source": [
        "config = [\n",
        "    (32, 3, 1),\n",
        "    (64, 3, 2),\n",
        "    [\"B\", 1],\n",
        "    (128, 3, 2),\n",
        "    [\"B\", 2],\n",
        "    (256, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (512, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (1024, 3, 2),\n",
        "    [\"B\", 4],  # To this point is Darknet-53\n",
        "    (512, 1, 1),\n",
        "    (1024, 3, 1),\n",
        "    \"S\",\n",
        "    (256, 1, 1),\n",
        "    \"U\",\n",
        "    (256, 1, 1),\n",
        "    (512, 3, 1),\n",
        "    \"S\",\n",
        "    (128, 1, 1),\n",
        "    \"U\",\n",
        "    (128, 1, 1),\n",
        "    (256, 3, 1),\n",
        "    \"S\",\n",
        "]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6QUUz3Bzymn"
      },
      "source": [
        "# Hyperparameters\n",
        "leakyReLuAlpha = 0.1\n",
        "bn_momentum = 0.999\n",
        "conv_bias = False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZEjRIB4z1HU"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class yolo_model(nn.Module):\n",
        "\n",
        "    def __init__(self, leakyReLuAlpha = 0.1, bn_momentum = 0.999, usebias = False):\n",
        "        super(yolo_model, self).__init__()\n",
        "        self.leakyReLuAlpha = leakyReLuAlpha\n",
        "        self.bn_momentum = bn_momentum\n",
        "        self.usebias = usebias\n",
        "        self.layers = self.createModelLayers()\n",
        "\n",
        "    def createModelLayers(self):\n",
        "        layers = nn.ModuleList()\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(3, 32, 3, 1, bias= self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(32, 64, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' residual '''\n",
        "        layer1 = nn.Conv2d(64, 32, 1, bias = self.usebias)\n",
        "        layer1 = nn.BatchNorm2d(32, momentum= self.bn_momentum)\n",
        "        layer1 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2 = nn.Conv2d(32, 64, 3, bias= self.usebias, padding=1)\n",
        "        layer2 = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer2 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        layer = nn.Sequential(layer1,layer2)\n",
        "        layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(64, 128, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 2 resiudal repeats '''\n",
        "        layer1 = nn.Conv2d(128, 64, 1, bias = self.usebias)\n",
        "        layer1 = nn.BatchNorm2d(64, momentum= self.bn_momentum)\n",
        "        layer1 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2 = nn.Conv2d(64, 128, 3, bias= self.usebias, padding=1)\n",
        "        layer2 = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer2 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1,layer2)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(128, 256, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1 = nn.Conv2d(256, 128, 1, bias = self.usebias)\n",
        "        layer1 = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layer1 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2 = nn.Conv2d(128, 256, 3, bias= self.usebias, padding=1)\n",
        "        layer2 = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer2 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1,layer2)\n",
        "          layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 512, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 8 residual repeats '''\n",
        "        layer1 = nn.Conv2d(512, 256, 1, bias = self.usebias)\n",
        "        layer1 = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layer1 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2 = nn.Conv2d(256, 512, 3, bias= self.usebias, padding=1)\n",
        "        layer2 = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer2 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1,layer2)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 1024, 3, 2, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' 4 residual repeats '''\n",
        "        layer1 = nn.Conv2d(1024, 512, 1, bias = self.usebias)\n",
        "        layer1 = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layer1 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "\n",
        "        layer2 = nn.Conv2d(512, 1024, 3, bias= self.usebias, padding=1)\n",
        "        layer2 = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layer2 = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        \n",
        "        for i in range(0,2):\n",
        "          layer = nn.Sequential(layer1,layer2)\n",
        "          layers.append(layer)\n",
        "        \n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(1024, 512, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(512, 1024, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(1024, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        layer = nn.Conv2d(1024, 512, kernel_size=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size= 3, padding=1),\n",
        "            nn.Conv2d(1024, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(512, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(768, 256, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(256, 512, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(512, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        layer = nn.Conv2d(512, 256, kernel_size=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size= 3, padding=1),\n",
        "            nn.Conv2d(512, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(256, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' upsampling '''\n",
        "        layer = nn.Upsample(scale_factor= 2)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' convs '''\n",
        "        layer = nn.Conv2d(384, 128, 1, 1, bias = self.usebias, padding=0)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(128, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        layer = nn.Conv2d(128, 256, 3, 1, bias = self.usebias, padding=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.BatchNorm2d(256, momentum= self.bn_momentum)\n",
        "        layers.append(layer)\n",
        "        layer = nn.LeakyReLU(negative_slope= self.leakyReLuAlpha)\n",
        "        layers.append(layer)\n",
        "\n",
        "        ''' scale prediction '''\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=1),\n",
        "            nn.Conv2d(128, 256, kernel_size=3)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        layer = nn.Conv2d(256, 128, kernel_size=1)\n",
        "        layers.append(layer)\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size= 3, padding=1),\n",
        "            nn.Conv2d(256, 24, kernel_size= 1)\n",
        "        )\n",
        "        layers.append(layer)\n",
        "        return layers\n",
        "\n",
        "    def evaluateModel(self, inputtensor):\n",
        "        route = []\n",
        "        output = []\n",
        "        x = self.layers[0](inputtensor)\n",
        "        print(x.shape)\n",
        "        x = self.layers[1](x)\n",
        "        x = self.layers[2](x)\n",
        "        \n",
        "        x = self.layers[3](x)\n",
        "        x = self.layers[4](x)\n",
        "        x = self.layers[5](x)\n",
        "        \n",
        "        x = self.layers[6](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[7](x)\n",
        "        x = self.layers[8](x)\n",
        "        x = self.layers[9](x)\n",
        "\n",
        "        x = self.layers[10](x)\n",
        "        x = self.layers[11](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[12](x)\n",
        "        x = self.layers[13](x)\n",
        "        x = self.layers[14](x)\n",
        "        \n",
        "        x = self.layers[15](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[16](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[17](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[18](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[19](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[20](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[21](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[22](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[23](x)\n",
        "        x = self.layers[24](x)\n",
        "        x = self.layers[25](x)\n",
        "        \n",
        "        x = self.layers[26](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[27](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[28](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[29](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[30](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[31](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[32](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[33](x)\n",
        "        route.append(x)\n",
        "        \n",
        "        x = self.layers[34](x)\n",
        "        x = self.layers[35](x)\n",
        "        x = self.layers[36](x)\n",
        "        \n",
        "        x = self.layers[37](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[38](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[39](x)\n",
        "        route.append(x)\n",
        "        x = self.layers[40](x)\n",
        "        route.append(x)\n",
        "\n",
        "        x = self.layers[41](x)\n",
        "        x = self.layers[42](x)\n",
        "        x = self.layers[43](x)\n",
        "        \n",
        "        x = self.layers[44](x)\n",
        "        x = self.layers[45](x)\n",
        "        x = self.layers[46](x)\n",
        "\n",
        "        x = self.layers[47](x)\n",
        "        xx = self.layers[48](x)\n",
        "        x = self.layers[49](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[50](x)\n",
        "        x = self.layers[51](x)\n",
        "        x = self.layers[52](x)\n",
        "        \n",
        "        x = self.layers[53](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[54](x)\n",
        "        x = self.layers[55](x)\n",
        "        x = self.layers[56](x)\n",
        "        \n",
        "        x = self.layers[57](x)\n",
        "        x = self.layers[58](x)\n",
        "        x = self.layers[59](x)\n",
        "        \n",
        "        x = self.layers[60](x)\n",
        "        xx = self.layers[61](x)\n",
        "        x = self.layers[62](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        x = self.layers[63](x)\n",
        "        x = self.layers[64](x)\n",
        "        x = self.layers[65](x)\n",
        "        \n",
        "        x = self.layers[66](x)\n",
        "        x = torch.cat([x, route[-1]], dim=1)\n",
        "        route.pop()\n",
        "\n",
        "        x = self.layers[67](x)\n",
        "        x = self.layers[68](x)\n",
        "        x = self.layers[69](x)\n",
        "        \n",
        "        x = self.layers[70](x)\n",
        "        x = self.layers[71](x)\n",
        "        x = self.layers[72](x)\n",
        "\n",
        "        x = self.layers[73](x)\n",
        "        xx = self.layers[74](x)\n",
        "        x = self.layers[75](xx)\n",
        "        x = x.reshape(xx.shape[0], 3, 8, xx.shape[2], xx.shape[3]).permute(0,1,3,4,2)\n",
        "        output.append(x)\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "H0D3Fe-2zndF",
        "outputId": "abd5cb0b-9185-4915-af8b-b9226692261e"
      },
      "source": [
        "model = yolo_model()\n",
        "\n",
        "data1 = torch.from_numpy(train_images[0])\n",
        "x = model.evaluateModel(data1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1c469bae169e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-c8ad2bc352cf>\u001b[0m in \u001b[0;36mevaluateModel\u001b[0;34m(self, inputtensor)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mroute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 3, 3, 3], but got 3-dimensional input of size [224, 224, 3] instead"
          ]
        }
      ]
    }
  ]
}